{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "OH4OSyH3skop",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TL5mfUm4syJ0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Multilayer Perceptron "
      ]
    },
    {
      "metadata": {
        "id": "eN1_edZNswYK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "yE_QAAittIzE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GgUINUo0tmQZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "5f4e0913-f88f-4370-aef3-4a5755b1e1f0"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-93d8da72a918>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IPbI2NYBtnUH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "learning_rate= 0.001\n",
        "training_epochs = 50\n",
        "batch_size = 10\n",
        "display_step = 1\n",
        "# Network parameter\n",
        "width  =28\n",
        "height = 28\n",
        "flat = height*width\n",
        "n_input= height*width\n",
        "n_hidden_1 = 256\n",
        "n_hidden_2= 256\n",
        "n_classes = 10\n",
        "# Input and output\n",
        "X = tf.placeholder(tf.float32, shape=[None, n_input])\n",
        "Y = tf.placeholder(tf.float32, shape=[None, n_classes])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8rBRgjfZu17r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "46TL-b8EvBFv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Store layers weight & bias\n",
        "weights = {\n",
        "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
        "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
        "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
        "}\n",
        "biases={\n",
        "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
        "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
        "    'out':tf.Variable(tf.random_normal([n_classes])) \n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IuUIln4mxedQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create model\n",
        "def multilayer_perceptron(x):\n",
        "  layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
        "  layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
        "  out_layer = tf.matmul(layer_2, weights['out'])+biases['out']\n",
        "  return out_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G2WeX5q4xfdp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "13dfe1fd-fcfc-42da-92f6-b01c8c963374"
      },
      "cell_type": "code",
      "source": [
        "# Construct model\n",
        "logits = multilayer_perceptron(X)\n",
        "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "# Initializing the variables\n",
        "init = tf.global_variables_initializer()\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  for epoch in range(training_epochs):\n",
        "    avg_cost= 0\n",
        "    total_batch= int(mnist.train.num_examples/batch_size)\n",
        "    for i in range(total_batch):\n",
        "      batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
        "      _, c = sess.run([train_op, loss_op], feed_dict={X:batch_x, Y: batch_y})\n",
        "      avg_cost +=c/total_batch\n",
        "    if epoch%display_step==0:\n",
        "      print(\"Epoch:\", \"%04d\"%(epoch+1), \"cost={:.9f}\".format(avg_cost))\n",
        "  print(\"Optimization Finished!\")\n",
        "# Test model\n",
        "  pred = tf.nn.softmax(logits)\n",
        "  correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(Y, 1))\n",
        "\n",
        "# Calculate accurary\n",
        "  accurary = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  print(\"Accurary:\", accurary.eval({X:mnist.test.images, Y:mnist.test.labels}))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 cost=165.057807488\n",
            "Epoch: 0002 cost=78.562322542\n",
            "Epoch: 0003 cost=58.739451151\n",
            "Epoch: 0004 cost=47.489713923\n",
            "Epoch: 0005 cost=40.015347818\n",
            "Epoch: 0006 cost=34.379450563\n",
            "Epoch: 0007 cost=30.447749995\n",
            "Epoch: 0008 cost=27.136583856\n",
            "Epoch: 0009 cost=24.653714675\n",
            "Epoch: 0010 cost=22.863608650\n",
            "Epoch: 0011 cost=21.293963007\n",
            "Epoch: 0012 cost=20.052441568\n",
            "Epoch: 0013 cost=18.776118606\n",
            "Epoch: 0014 cost=17.646182039\n",
            "Epoch: 0015 cost=16.720625100\n",
            "Epoch: 0016 cost=15.847718932\n",
            "Epoch: 0017 cost=14.854909516\n",
            "Epoch: 0018 cost=14.085203423\n",
            "Epoch: 0019 cost=13.448182639\n",
            "Epoch: 0020 cost=12.814833759\n",
            "Epoch: 0021 cost=12.276647021\n",
            "Epoch: 0022 cost=11.475711801\n",
            "Epoch: 0023 cost=11.061195459\n",
            "Epoch: 0024 cost=10.415391955\n",
            "Epoch: 0025 cost=10.063829785\n",
            "Epoch: 0026 cost=9.515111806\n",
            "Epoch: 0027 cost=9.115835304\n",
            "Epoch: 0028 cost=8.634803654\n",
            "Epoch: 0029 cost=8.199377259\n",
            "Epoch: 0030 cost=7.838775187\n",
            "Epoch: 0031 cost=7.437354064\n",
            "Epoch: 0032 cost=7.176634787\n",
            "Epoch: 0033 cost=6.754681740\n",
            "Epoch: 0034 cost=6.468980103\n",
            "Epoch: 0035 cost=6.116024850\n",
            "Epoch: 0036 cost=5.832835117\n",
            "Epoch: 0037 cost=5.616157745\n",
            "Epoch: 0038 cost=5.179061662\n",
            "Epoch: 0039 cost=4.998180115\n",
            "Epoch: 0040 cost=4.730547563\n",
            "Epoch: 0041 cost=4.410962500\n",
            "Epoch: 0042 cost=4.207494387\n",
            "Epoch: 0043 cost=4.039845629\n",
            "Epoch: 0044 cost=3.771000389\n",
            "Epoch: 0045 cost=3.509527885\n",
            "Epoch: 0046 cost=3.342003279\n",
            "Epoch: 0047 cost=3.116515005\n",
            "Epoch: 0048 cost=2.994591806\n",
            "Epoch: 0049 cost=2.773702530\n",
            "Epoch: 0050 cost=2.595265947\n",
            "Optimization Finished!\n",
            "Accurary: 0.8871\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9oxI18ue04xP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dl7TtzitHt2s",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "b64a32a3-2ca3-4b43-9785-b94a95b955a2"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e9fa40a9-dee0-4494-857e-f298b85040db\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-e9fa40a9-dee0-4494-857e-f298b85040db\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving testmnist.csv to testmnist.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FuubM35m4a9u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Convolution Neural Network"
      ]
    },
    {
      "metadata": {
        "id": "MJalDTQA3-Xr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "f1242928-380b-4eb9-b43d-6a6b86f2f98f"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"tmp/data\", one_hot=True)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Extracting tmp/data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Extracting tmp/data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting tmp/data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YzG4Lo9V41q-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Training Parameters\n",
        "learning_rate = 0.003\n",
        "num_steps= 1000\n",
        "batch_size=128\n",
        "display_step=10\n",
        "\n",
        "# Network Parameters\n",
        "num_input= 784\n",
        "num_classes = 10\n",
        "dropout= 0.75\n",
        "\n",
        "X= tf.placeholder(tf.float32, [None, num_input])\n",
        "Y= tf.placeholder(tf.float32, [None, num_classes])\n",
        "keep_prob = tf.placeholder(tf.float32)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HJLo718Y5fWn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create some wrappers for simplicity\n",
        "def conv2d(x, W, b, strides=1):\n",
        "    # Conv2D wrapper, with bias and relu activation\n",
        "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
        "    x = tf.nn.bias_add(x, b)\n",
        "    return tf.nn.relu(x)\n",
        "\n",
        "\n",
        "def maxpool2d(x, k=2):\n",
        "    # MaxPool2D wrapper\n",
        "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
        "                          padding='SAME')\n",
        "\n",
        "\n",
        "# Create model\n",
        "def conv_net(x, weights, biases, dropout):\n",
        "    # MNIST data input is a 1-D vector of 784 features (28*28 pixels)\n",
        "    # Reshape to match picture format [Height x Width x Channel]\n",
        "    # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n",
        "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
        "\n",
        "    # Convolution Layer\n",
        "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
        "    # Max Pooling (down-sampling)\n",
        "    conv1 = maxpool2d(conv1, k=2)\n",
        "\n",
        "    # Convolution Layer\n",
        "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
        "    # Max Pooling (down-sampling)\n",
        "    conv2 = maxpool2d(conv2, k=2)\n",
        "\n",
        "    # Fully connected layer\n",
        "    # Reshape conv2 output to fit fully connected layer input\n",
        "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
        "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
        "    fc1 = tf.nn.relu(fc1)\n",
        "    # Apply Dropout\n",
        "    fc1 = tf.nn.dropout(fc1, dropout)\n",
        "\n",
        "    # Output, class prediction\n",
        "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vSNhjvAu-7Ra",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1768
        },
        "outputId": "05d0626e-8ff9-4f3b-e3c9-b6d58535e522"
      },
      "cell_type": "code",
      "source": [
        "# Store layers weight & bias\n",
        "weights = {\n",
        "    # 5x5 conv, 1 input, 32 outputs\n",
        "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
        "    # 5x5 conv, 32 inputs, 64 outputs\n",
        "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
        "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
        "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
        "    # 1024 inputs, 10 outputs (class prediction)\n",
        "    'out': tf.Variable(tf.random_normal([1024, num_classes]))\n",
        "}\n",
        "\n",
        "biases = {\n",
        "    'bc1': tf.Variable(tf.random_normal([32])),\n",
        "    'bc2': tf.Variable(tf.random_normal([64])),\n",
        "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
        "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
        "}\n",
        "\n",
        "# Construct model\n",
        "logits = conv_net(X, weights, biases, keep_prob)\n",
        "prediction = tf.nn.softmax(logits)\n",
        "\n",
        "# Define loss and optimizer\n",
        "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
        "    logits=logits, labels=Y))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "\n",
        "# Evaluate model\n",
        "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "# Initialize the variables (i.e. assign their default value)\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Start training# Start \n",
        "with tf.Session() as sess:\n",
        "\n",
        "    # Run the initializer\n",
        "    sess.run(init)\n",
        "\n",
        "    for step in range(1, num_steps+1):\n",
        "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
        "        # Run optimization op (backprop)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, keep_prob: dropout})\n",
        "        if step % display_step == 0 or step == 1:\n",
        "            # Calculate batch loss and accuracy\n",
        "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
        "                                                                 Y: batch_y,\n",
        "                                                                 keep_prob: 1.0})\n",
        "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
        "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
        "                  \"{:.3f}\".format(acc))\n",
        "\n",
        "    print(\"Optimization Finished!\")\n",
        "    \n",
        "    # Calculate accuracy for 256 MNIST test images\n",
        "    print(\"Testing Accuracy:\", \\\n",
        "        sess.run(accuracy, feed_dict={X: mnist.test.images[:256],\n",
        "                                      Y: mnist.test.labels[:256],\n",
        "                                      keep_prob: 1.0}))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 1, Minibatch Loss= 57075.8359, Training Accuracy= 0.148\n",
            "Step 10, Minibatch Loss= 4868.1460, Training Accuracy= 0.672\n",
            "Step 20, Minibatch Loss= 4017.6157, Training Accuracy= 0.836\n",
            "Step 30, Minibatch Loss= 2215.9648, Training Accuracy= 0.883\n",
            "Step 40, Minibatch Loss= 1818.1929, Training Accuracy= 0.906\n",
            "Step 50, Minibatch Loss= 1968.1517, Training Accuracy= 0.898\n",
            "Step 60, Minibatch Loss= 1143.1051, Training Accuracy= 0.891\n",
            "Step 70, Minibatch Loss= 1316.0112, Training Accuracy= 0.914\n",
            "Step 80, Minibatch Loss= 1435.0190, Training Accuracy= 0.922\n",
            "Step 90, Minibatch Loss= 1125.3888, Training Accuracy= 0.930\n",
            "Step 100, Minibatch Loss= 714.3336, Training Accuracy= 0.906\n",
            "Step 110, Minibatch Loss= 854.2839, Training Accuracy= 0.930\n",
            "Step 120, Minibatch Loss= 985.0384, Training Accuracy= 0.891\n",
            "Step 130, Minibatch Loss= 319.9572, Training Accuracy= 0.961\n",
            "Step 140, Minibatch Loss= 211.2625, Training Accuracy= 0.969\n",
            "Step 150, Minibatch Loss= 888.2336, Training Accuracy= 0.906\n",
            "Step 160, Minibatch Loss= 821.9213, Training Accuracy= 0.938\n",
            "Step 170, Minibatch Loss= 566.3066, Training Accuracy= 0.945\n",
            "Step 180, Minibatch Loss= 489.9836, Training Accuracy= 0.938\n",
            "Step 190, Minibatch Loss= 959.2018, Training Accuracy= 0.914\n",
            "Step 200, Minibatch Loss= 124.5449, Training Accuracy= 0.984\n",
            "Step 210, Minibatch Loss= 163.4945, Training Accuracy= 0.969\n",
            "Step 220, Minibatch Loss= 344.2567, Training Accuracy= 0.969\n",
            "Step 230, Minibatch Loss= 80.7390, Training Accuracy= 0.977\n",
            "Step 240, Minibatch Loss= 71.3518, Training Accuracy= 0.984\n",
            "Step 250, Minibatch Loss= 297.9787, Training Accuracy= 0.938\n",
            "Step 260, Minibatch Loss= 637.2438, Training Accuracy= 0.930\n",
            "Step 270, Minibatch Loss= 292.2126, Training Accuracy= 0.969\n",
            "Step 280, Minibatch Loss= 312.0267, Training Accuracy= 0.953\n",
            "Step 290, Minibatch Loss= 295.4143, Training Accuracy= 0.945\n",
            "Step 300, Minibatch Loss= 343.4541, Training Accuracy= 0.977\n",
            "Step 310, Minibatch Loss= 173.1080, Training Accuracy= 0.961\n",
            "Step 320, Minibatch Loss= 375.5789, Training Accuracy= 0.945\n",
            "Step 330, Minibatch Loss= 172.8178, Training Accuracy= 0.984\n",
            "Step 340, Minibatch Loss= 251.6012, Training Accuracy= 0.977\n",
            "Step 350, Minibatch Loss= 247.0710, Training Accuracy= 0.969\n",
            "Step 360, Minibatch Loss= 78.1001, Training Accuracy= 0.953\n",
            "Step 370, Minibatch Loss= 169.1734, Training Accuracy= 0.977\n",
            "Step 380, Minibatch Loss= 353.1765, Training Accuracy= 0.945\n",
            "Step 390, Minibatch Loss= 476.7727, Training Accuracy= 0.961\n",
            "Step 400, Minibatch Loss= 116.7058, Training Accuracy= 0.977\n",
            "Step 410, Minibatch Loss= 338.3807, Training Accuracy= 0.977\n",
            "Step 420, Minibatch Loss= 243.2648, Training Accuracy= 0.969\n",
            "Step 430, Minibatch Loss= 408.5042, Training Accuracy= 0.938\n",
            "Step 440, Minibatch Loss= 59.7791, Training Accuracy= 0.961\n",
            "Step 450, Minibatch Loss= 336.9871, Training Accuracy= 0.945\n",
            "Step 460, Minibatch Loss= 216.3186, Training Accuracy= 0.977\n",
            "Step 470, Minibatch Loss= 340.5022, Training Accuracy= 0.961\n",
            "Step 480, Minibatch Loss= 127.4541, Training Accuracy= 0.953\n",
            "Step 490, Minibatch Loss= 114.6967, Training Accuracy= 0.977\n",
            "Step 500, Minibatch Loss= 10.4979, Training Accuracy= 0.984\n",
            "Step 510, Minibatch Loss= 27.7900, Training Accuracy= 0.984\n",
            "Step 520, Minibatch Loss= 46.3529, Training Accuracy= 0.992\n",
            "Step 530, Minibatch Loss= 17.3689, Training Accuracy= 0.992\n",
            "Step 540, Minibatch Loss= 239.6394, Training Accuracy= 0.969\n",
            "Step 550, Minibatch Loss= 12.3954, Training Accuracy= 0.992\n",
            "Step 560, Minibatch Loss= 39.9617, Training Accuracy= 0.977\n",
            "Step 570, Minibatch Loss= 218.1944, Training Accuracy= 0.969\n",
            "Step 580, Minibatch Loss= 187.6418, Training Accuracy= 0.961\n",
            "Step 590, Minibatch Loss= 248.5720, Training Accuracy= 0.938\n",
            "Step 600, Minibatch Loss= 287.6827, Training Accuracy= 0.945\n",
            "Step 610, Minibatch Loss= 63.0289, Training Accuracy= 0.992\n",
            "Step 620, Minibatch Loss= 52.1493, Training Accuracy= 0.992\n",
            "Step 630, Minibatch Loss= 62.1352, Training Accuracy= 0.984\n",
            "Step 640, Minibatch Loss= 198.0648, Training Accuracy= 0.961\n",
            "Step 650, Minibatch Loss= 273.6071, Training Accuracy= 0.961\n",
            "Step 660, Minibatch Loss= 213.5137, Training Accuracy= 0.961\n",
            "Step 670, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
            "Step 680, Minibatch Loss= 5.7046, Training Accuracy= 0.992\n",
            "Step 690, Minibatch Loss= 97.4798, Training Accuracy= 0.977\n",
            "Step 700, Minibatch Loss= 92.7644, Training Accuracy= 0.969\n",
            "Step 710, Minibatch Loss= 288.2993, Training Accuracy= 0.969\n",
            "Step 720, Minibatch Loss= 151.4234, Training Accuracy= 0.984\n",
            "Step 730, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
            "Step 740, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
            "Step 750, Minibatch Loss= 131.4460, Training Accuracy= 0.977\n",
            "Step 760, Minibatch Loss= 62.8315, Training Accuracy= 0.977\n",
            "Step 770, Minibatch Loss= 42.2076, Training Accuracy= 0.984\n",
            "Step 780, Minibatch Loss= 89.4896, Training Accuracy= 0.984\n",
            "Step 790, Minibatch Loss= 75.4414, Training Accuracy= 0.977\n",
            "Step 800, Minibatch Loss= 51.0610, Training Accuracy= 0.969\n",
            "Step 810, Minibatch Loss= 27.5069, Training Accuracy= 0.984\n",
            "Step 820, Minibatch Loss= 11.7978, Training Accuracy= 0.992\n",
            "Step 830, Minibatch Loss= 13.8312, Training Accuracy= 0.992\n",
            "Step 840, Minibatch Loss= 19.9221, Training Accuracy= 0.992\n",
            "Step 850, Minibatch Loss= 53.0708, Training Accuracy= 0.992\n",
            "Step 860, Minibatch Loss= 115.4574, Training Accuracy= 0.977\n",
            "Step 870, Minibatch Loss= 125.4913, Training Accuracy= 0.977\n",
            "Step 880, Minibatch Loss= 52.9745, Training Accuracy= 0.992\n",
            "Step 890, Minibatch Loss= 84.5736, Training Accuracy= 0.977\n",
            "Step 900, Minibatch Loss= 85.1409, Training Accuracy= 0.977\n",
            "Step 910, Minibatch Loss= 257.9925, Training Accuracy= 0.961\n",
            "Step 920, Minibatch Loss= 34.3809, Training Accuracy= 0.984\n",
            "Step 930, Minibatch Loss= 79.0423, Training Accuracy= 0.984\n",
            "Step 940, Minibatch Loss= 161.7099, Training Accuracy= 0.961\n",
            "Step 950, Minibatch Loss= 54.4907, Training Accuracy= 0.984\n",
            "Step 960, Minibatch Loss= 36.6696, Training Accuracy= 0.969\n",
            "Step 970, Minibatch Loss= 95.2033, Training Accuracy= 0.969\n",
            "Step 980, Minibatch Loss= 0.3804, Training Accuracy= 0.992\n",
            "Step 990, Minibatch Loss= 15.2418, Training Accuracy= 0.992\n",
            "Step 1000, Minibatch Loss= 235.2566, Training Accuracy= 0.961\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.9921875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rCgjN_MpJBcu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Recurrent Neural Network"
      ]
    },
    {
      "metadata": {
        "id": "CHL2AVL4BAXa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "329b7191-5bb3-4f0b-d49d-ecd5da4a7fcf"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib import rnn\n",
        "tf.reset_default_graph()\n",
        "# Import MNIST data\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lofLSdOiP_9f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Training Parameters# Train \n",
        "learning_rate = 0.001\n",
        "training_steps = 10000\n",
        "batch_size = 128\n",
        "display_step = 200\n",
        "\n",
        "# Network Parameters\n",
        "num_input = 28 # MNIST data input (img shape: 28*28)\n",
        "timesteps = 28 # timesteps\n",
        "num_hidden = 128 # hidden layer num of features\n",
        "num_classes = 10 # MNIST total classes (0-9 digits)\n",
        "\n",
        "# tf Graph input\n",
        "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
        "Y = tf.placeholder(\"float\", [None, num_classes])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jPexr_wiPr6Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define weights\n",
        "weights={\n",
        "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
        "}\n",
        "biases={\n",
        "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vHivbGkHN1h_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def RNN(x, weights, biases):\n",
        "\n",
        "    # Prepare data shape to match `rnn` function requirements\n",
        "    # Current data input shape: (batch_size, timesteps, n_input)\n",
        "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
        "\n",
        "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
        "    x = tf.unstack(x, timesteps, 1)\n",
        "\n",
        "    # Define a lstm cell with tensorflow\n",
        "    lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
        "\n",
        "    # Get lstm cell output\n",
        "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
        "\n",
        "    # Linear activation, using rnn inner loop last output\n",
        "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JpkCon8BJayq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1543
        },
        "outputId": "48f2d396-e284-465b-bd58-62f33e7d8e86"
      },
      "cell_type": "code",
      "source": [
        "logits = RNN(X, weights, biases)\n",
        "prediction = tf.nn.softmax(logits)\n",
        "\n",
        "# Define loss and optimizer\n",
        "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
        "    logits=logits, labels=Y))\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "# Evaluate model (with test logits, for dropout to be disabled)\n",
        "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "# Initialize the variables (i.e. assign their default value)\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  # Run the initializer\n",
        "  sess.run(init)\n",
        "  for step in range(1, training_steps+1):\n",
        "    batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
        "    \n",
        "    batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
        "    # Run optimization op(backprop)\n",
        "    sess.run(train_op, feed_dict={X:batch_x, Y:batch_y})\n",
        "    if(step%display_step==0 or step==1):\n",
        "      loss, acc = sess.run([loss_op, accurary], feed_dict={X:batch_x, Y:batch_y})\n",
        "      print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
        "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
        "                  \"{:.3f}\".format(acc))\n",
        "  print(\"Optimization Finished!\")\n",
        "\n",
        "  # Calculate accuracy for 128 mnist test images\n",
        "  test_len = 128\n",
        "  test_data = mnist.test.images[:test_len].reshape((-1, timesteps, num_input))\n",
        "  test_label = mnist.test.labels[:test_len]\n",
        "  print(\"Testing Accuracy:\", \\\n",
        "    sess.run(accuracy, feed_dict={X: test_data, Y: test_label}))\n",
        "                       "
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    281\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 282\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    283\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3338\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3339\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3417\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3418\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3419\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Tensor Tensor(\"Mean_19:0\", shape=(), dtype=float32) is not an element of this graph.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-b604ebbbadd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mdisplay_step\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccurary\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Step \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", Minibatch Loss= \"\u001b[0m \u001b[0;34m+\u001b[0m                   \u001b[0;34m\"{:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", Training Accuracy= \"\u001b[0m \u001b[0;34m+\u001b[0m                   \u001b[0;34m\"{:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Optimization Finished!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1083\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1085\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \"\"\"\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m       \u001b[0;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_ListFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_DictFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches)\u001b[0m\n\u001b[1;32m    350\u001b[0m     \"\"\"\n\u001b[1;32m    351\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    350\u001b[0m     \"\"\"\n\u001b[1;32m    351\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' % (fetch,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n\u001b[0;32m--> 289\u001b[0;31m                          'Tensor. (%s)' % (fetch, str(e)))\n\u001b[0m\u001b[1;32m    290\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
            "\u001b[0;31mValueError\u001b[0m: Fetch argument <tf.Tensor 'Mean_19:0' shape=() dtype=float32> cannot be interpreted as a Tensor. (Tensor Tensor(\"Mean_19:0\", shape=(), dtype=float32) is not an element of this graph.)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Pu_3zDOVS4KT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Auto-Encoder"
      ]
    },
    {
      "metadata": {
        "id": "dmk9sqXqQHYh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "386f87a2-6482-456e-aff5-5b09140ef239"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import MNIST data\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aluroK7STAvV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Training Parameters\n",
        "learning_rate=0.01\n",
        "num_steps= 3000\n",
        "display_step=1000\n",
        "examples_to_show=10\n",
        "\n",
        "# Network Parameters\n",
        "num_hidden_1=256\n",
        "num_hidden_2=128\n",
        "num_input=784\n",
        "\n",
        "#tf Graph input (only pictures)\n",
        "X = tf.placeholder(\"float\", [None, num_input])\n",
        "\n",
        "weights={\n",
        "    'encoder_h1': tf.Variable(tf.random_normal([num_input, num_hidden_1])),\n",
        "    'encoder_h2': tf.Variable(tf.random_normal([num_hidden_1, num_hidden_2])),\n",
        "    'decoder_h1': tf.Variable(tf.random_normal([num_hidden_2, num_hidden_1])),\n",
        "    'decoder_h2': tf.Variable(tf.random_normal([num_hidden_1, num_input])),\n",
        "}\n",
        "\n",
        "biases={\n",
        "    'encoder_b1': tf.Variable(tf.random_normal([num_hidden_1])),\n",
        "    'encoder_b2': tf.Variable(tf.random_normal([num_hidden_2])),\n",
        "    'decoder_b1': tf.Variable(tf.random_normal([num_hidden_1])),\n",
        "    'decoder_b2': tf.Variable(tf.random_normal([num_input])),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zWNVM-ZXYd8e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "55974a83-77a6-46bb-8f30-1020692cbf14"
      },
      "cell_type": "code",
      "source": [
        "def encoder(x):\n",
        "  layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']), biases['encoder_b1']))\n",
        "  layer_2= tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']), biases['encoder_b2']))\n",
        "  return layer_2\n",
        "def decoder(x):\n",
        "  layer_1= tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']), biases['decoder_b1']))\n",
        "  layer_2= tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']), biases['decoder_b2']))\n",
        "  return layer_2\n",
        "\n",
        "# Construct model\n",
        "encoder_op = encoder(X)\n",
        "decoder_op = decoder(encoder_op)\n",
        "\n",
        "y_pred = decoder_op\n",
        "y_true=X\n",
        "loss = tf.reduce_mean(tf.pow(y_true-y_pred, 2))\n",
        "optimizer= tf.train.RMSPropOptimizer(learning_rate).minimize(loss)\n",
        "init = tf.global_variables_initializer()\n",
        "# Start Training \n",
        "# Start a new TF session\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "for i in range(1, num_steps+1):\n",
        "  batch_x, _ = mnist.train.next_batch(batch_size)\n",
        "  _, l = sess.run([optimizer, loss], feed_dict={X: batch_x})\n",
        "  \n",
        "  if(i%display_step==0 or i==1):\n",
        "    print(\"Step %i: Minibatch Loss: %f\"%(i, l))\n",
        "  \n",
        "\n",
        "  "
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 1: Minibatch Loss: 0.465861\n",
            "Step 1000: Minibatch Loss: 0.134085\n",
            "Step 2000: Minibatch Loss: 0.109898\n",
            "Step 3000: Minibatch Loss: 0.099270\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Fi1NtkGJs8Jy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Variational Auto-Encoder"
      ]
    },
    {
      "metadata": {
        "id": "UD9qvaKblUca",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PavaFdbXtT-D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "97cfa2c4-71c9-4d02-f852-783689a4fb73"
      },
      "cell_type": "code",
      "source": [
        "# Import MNIST data\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DiBX9g8vtWbb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "learning_rate = 0.001\n",
        "num_steps = 30000\n",
        "batch_size=64\n",
        "\n",
        "# Network Parameters\n",
        "image_dim= 784\n",
        "hidden_dim = 512\n",
        "latent_dim= 2\n",
        "def glorot_init(shape):\n",
        "  return tf.random_normal(shape=shape, stddev=1./tf.sqrt(shape[0]/2.))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qgeEFoH71sLX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "urxxIZFquED-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "4353dd09-2571-4296-a02f-0d3f2ef998eb"
      },
      "cell_type": "code",
      "source": [
        "# Variables\n",
        "weights={\n",
        "    'encoder_h1': tf.Variable(glorot_init([image_dim, hidden_dim])),\n",
        "    'z_mean': tf.Variable(glorot_init([hidden_dim, latent_dim])),\n",
        "    'z_std': tf.Variable(glorot_init([hidden_dim, latent_dim])),\n",
        "    'decoder_h1': tf.Variable(glorot_init([latent_dim, hidden_dim])),\n",
        "    'decoder_out': tf.Variable(glorot_inti([hidden_dim, image_dim]))\n",
        "}\n",
        "biases={\n",
        "    'encoder_b1': tf.Variable(glorot_init([hidden_dim])),\n",
        "    'z_mean': tf.Varialbe(glorot_init([latent_dim])),\n",
        "    'z_std': tf.Varialbe(glorot_init(latent_dim)),\n",
        "    'decoder_b1': tf.Variable(glorot_init([hidden_dim])),\n",
        "    'decoder_out': tf.Variable(glorot_init([image_dim]))\n",
        "}"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-100-61e93e0f5d65>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    'z_mean': tf.Varialbe(glorot_init([latent_dim]))\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "_wxdwB9-wAee",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}